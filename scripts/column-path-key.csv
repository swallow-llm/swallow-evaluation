column,path,key,max_score
XLSUM_ja_1shot,ja/xlsum/xlsum_1shot_allcases/score_xlsum.json,results.xlsum_ja.rouge2,100
MATH (mgsm_ja),ja/mgsm/math_4shot_allcases/score_math.json,results.mgsm.acc,1
wmt20_en_ja_bleu,ja/wmt20_en_ja/wmt20_en_ja_4shot_allcases/score_wmt20_en_ja.json,results.wmt20-en-ja.bleu,100
wmt20_ja_en_bleu,ja/wmt20_ja_en/wmt20_ja_en_4shot_allcases/score_wmt20_ja_en.json,results.wmt20-ja-en.bleu,100
MC,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,x,1
NLI,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,x,1
QA,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,x,1
RC,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,x,1
jamp (NLI),ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jamp_exact_match,1
janli (NLI),ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.janli_exact_match,1
jcommonsenseqa,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jcommonsenseqa_exact_match,1
jemhopqa,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jemhopqa_char_f1,1
jnli,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jnli_exact_match,1
jsem,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jsem_exact_match,1
jsick (NLI),ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jsick_exact_match,1
jsquad,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jsquad_char_f1,1
jsts_pearson,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jsts_pearson,1
jsts_spearman,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.jsts_spearman,1
niilc,ja/llmjp/4shot_-1cases/llm_jp_eval_general.json,scores.niilc_char_f1,1
jmmlu,ja/llmjp/5shot_-1cases/llm_jp_eval_jmmlu_per_task.json,results.jmmlu,1
jmmlu_social_sciences,ja/llmjp/5shot_-1cases/llm_jp_eval_jmmlu_per_task.json,results.jmmlu_social_sciences,1
jmmlu_humanities,ja/llmjp/5shot_-1cases/llm_jp_eval_jmmlu_per_task.json,results.jmmlu_humanities,1
jmmlu_stem,ja/llmjp/5shot_-1cases/llm_jp_eval_jmmlu_per_task.json,results.jmmlu_stem,1
jmmlu_other,ja/llmjp/5shot_-1cases/llm_jp_eval_jmmlu_per_task.json,results.jmmlu_other,1
jhumaneval@1,ja/humaneval/metrics.json,humaneval.pass@1,1
jhumaneval@10,ja/humaneval/metrics.json,humaneval.pass@10,1
jhumaneval_answer@10,ja/humaneval/metrics.json,humaneval.answer@10,1
MT-Bench (ALL),ja/ja_mt_bench/judge.json,MODEL_NAME.overall.average.score,10
writing,ja/ja_mt_bench/judge.json,MODEL_NAME.Writing.average.score,10
roleplay,ja/ja_mt_bench/judge.json,MODEL_NAME.Roleplay.average.score,10
reasoning,ja/ja_mt_bench/judge.json,MODEL_NAME.Reasoning.average.score,10
math,ja/ja_mt_bench/judge.json,MODEL_NAME.Math.average.score,10
coding,ja/ja_mt_bench/judge.json,MODEL_NAME.Coding.average.score,10
extraction,ja/ja_mt_bench/judge.json,MODEL_NAME.Extraction.average.score,10
stem,ja/ja_mt_bench/judge.json,MODEL_NAME.STEM.average.score,10
humanities,ja/ja_mt_bench/judge.json,MODEL_NAME.Humanities.average.score,10
gsm8k,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.gsm8k.exact_match,strict-match",1
squad2,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.squadv2.exact,none",100
triviaqa,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.triviaqa.exact_match,remove_whitespace",1
hellaswag,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.hellaswag.acc,none",1
openbookqa,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.openbookqa.acc,none",1
xwinograd_en,en/harness_en/alltasks_4shot_allcases/general/results.json,"results.xwinograd_en.acc,none",1
bbh_cot,en/harness_en/alltasks_3shot_allcases/bbh_cot/results.json,"results.bbh_cot_fewshot.exact_match,get-answer",1
mmlu,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu.acc,none",1
mmlu_social_sciences,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_social_sciences.acc,none",1
mmlu_humanities,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_humanities.acc,none",1
mmlu_stem,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_stem.acc,none",1
mmlu_other,en/harness_en/alltasks_5shot_allcases/mmlu/results.json,"groups.mmlu_other.acc,none",1
humaneval@1,en/humaneval/metrics.json,humaneval.pass@1,1
humaneval@10,en/humaneval/metrics.json,humaneval.pass@10,1
humaneval_answer@10,en/humaneval/metrics.json,humaneval.answer@10,1
jhumaneval-unstripped@1,ja/humaneval-unstripped/metrics.json,humaneval.pass@1,1
jhumaneval-unstripped@10,ja/humaneval-unstripped/metrics.json,humaneval.pass@10,1
jhumaneval-unstripped_answer@10,ja/humaneval-unstripped/metrics.json,humaneval.answer@10,1
humaneval-unstripped@1,en/humaneval-unstripped/metrics.json,humaneval.pass@1,1
humaneval-unstripped@10,en/humaneval-unstripped/metrics.json,humaneval.pass@10,1
humaneval-unstripped_answer@10,en/humaneval-unstripped/metrics.json,humaneval.answer@10,1